{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the Semeval data and return a dataframe\n",
    "def read_semeval_data(filename):\n",
    "    '''\n",
    "    Description: reads Semantic Evaluation XML dataset and converts into a \n",
    "                 dataframe\n",
    "    Arguments:\n",
    "                 filename: string with file path (including filename)\n",
    "    Returns :    pandas data frame\n",
    "    Important:   this function only puts positive and neutral reviews in dataframe                          \n",
    "    '''\n",
    "    f = open(filename, 'r')\n",
    "    raw_training_data = f.read()\n",
    "    xmldoc = BeautifulSoup(raw_training_data,'lxml-xml')\n",
    "    sentences = xmldoc.Reviews.find_all('sentences')\n",
    "    opinions = xmldoc.Reviews.find_all('Opinions')\n",
    "    reviews = []\n",
    "    for i in range(0,len(sentences)):\n",
    "        record = {}\n",
    "        entity_aspect_pairs = opinions[i].find_all('Opinion')\n",
    "        for ea_pair in entity_aspect_pairs:\n",
    "            ea = ea_pair.attrs['category']\n",
    "            polarity = ea_pair.attrs['polarity']\n",
    "            if(polarity == 'positive'):\n",
    "                record[ea] = 1\n",
    "            elif(polarity == 'negative'):\n",
    "                record[ea] = -1\n",
    "            else:\n",
    "                record[ea] = 0           \n",
    "        record['TEXT'] = sentences[i].get_text()\n",
    "        reviews.append(record)\n",
    "    #Create a dataframe\n",
    "    df=pd.DataFrame(reviews)\n",
    "    #Change order of the columns so that text appears first\n",
    "    cols = df.columns.tolist()\n",
    "    cols.sort()\n",
    "    cols.reverse()\n",
    "    df = df[cols]\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "entity_labels = ['Food','Drinks','Service','Ambience','Location','Restaurant']\n",
    "<br/>attributes_labels = ['General','Prices','Quality','Style&Options','Miscellaneous']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Possible Combinations of Entities and Attributes #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/entity_attributes_combinations.jpg' style='width:50;height:50'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>SERVICE#GENERAL</th>\n",
       "      <th>RESTAURANT#PRICES</th>\n",
       "      <th>RESTAURANT#MISCELLANEOUS</th>\n",
       "      <th>RESTAURANT#GENERAL</th>\n",
       "      <th>LOCATION#GENERAL</th>\n",
       "      <th>FOOD#STYLE_OPTIONS</th>\n",
       "      <th>FOOD#QUALITY</th>\n",
       "      <th>FOOD#PRICES</th>\n",
       "      <th>DRINKS#STYLE_OPTIONS</th>\n",
       "      <th>DRINKS#QUALITY</th>\n",
       "      <th>DRINKS#PRICES</th>\n",
       "      <th>AMBIENCE#GENERAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nYum!\\n\\n\\nServes really good sushi.\\n\\n\\nN...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nNo Comparison\\n\\n\\n– I can't say enough ab...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\nSnotty Attitude\\n\\n\\n– We were treated ver...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\nGood food!\\n\\n\\n– We love breakfast food.\\...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\nOverrated\\n\\n\\n– I was highly disappointed...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TEXT  SERVICE#GENERAL  \\\n",
       "0  \\n\\nYum!\\n\\n\\nServes really good sushi.\\n\\n\\nN...              0.0   \n",
       "1  \\n\\nNo Comparison\\n\\n\\n– I can't say enough ab...              1.0   \n",
       "2  \\n\\nSnotty Attitude\\n\\n\\n– We were treated ver...             -1.0   \n",
       "3  \\n\\nGood food!\\n\\n\\n– We love breakfast food.\\...              1.0   \n",
       "4  \\n\\nOverrated\\n\\n\\n– I was highly disappointed...              0.0   \n",
       "\n",
       "   RESTAURANT#PRICES  RESTAURANT#MISCELLANEOUS  RESTAURANT#GENERAL  \\\n",
       "0                0.0                       0.0                   1   \n",
       "1                0.0                       0.0                   1   \n",
       "2                0.0                       0.0                  -1   \n",
       "3                0.0                       0.0                   1   \n",
       "4               -1.0                       0.0                  -1   \n",
       "\n",
       "   LOCATION#GENERAL  FOOD#STYLE_OPTIONS  FOOD#QUALITY  FOOD#PRICES  \\\n",
       "0               0.0                 0.0           1.0          0.0   \n",
       "1               0.0                 0.0           1.0          0.0   \n",
       "2               0.0                 0.0           0.0          0.0   \n",
       "3               0.0                 0.0           1.0          0.0   \n",
       "4               0.0                -1.0          -1.0          0.0   \n",
       "\n",
       "   DRINKS#STYLE_OPTIONS  DRINKS#QUALITY  DRINKS#PRICES  AMBIENCE#GENERAL  \n",
       "0                   0.0             0.0            0.0               0.0  \n",
       "1                   0.0             0.0            0.0               0.0  \n",
       "2                   0.0             0.0            0.0               0.0  \n",
       "3                   0.0             0.0            0.0               0.0  \n",
       "4                   0.0             0.0            0.0               1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training = read_semeval_data('data/train.xml')\n",
    "df_testing = read_semeval_data('data/test.xml')\n",
    "df_testing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataframe above a +1 indicates a positive polarity and -1 indicates negative polarity whereas 0 means that this aspect is not found or found to be neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to clean the text data\n",
    "#Remove punctuations, newline characters and convert to lowercase.\n",
    "#Note that we are not removing dot to mark sentence boundary\n",
    "def clean_text_data(data):\n",
    "    '''\n",
    "    Description: Given text returns cleaned version\n",
    "    Arguments:\n",
    "                  data: string with raw review text\n",
    "    Returns  :\n",
    "                  cleaned: string with unwanted characters removed\n",
    "    '''\n",
    "    prog = re.compile('[\\t\\n\\r\\f\\v\\d\\']', re.UNICODE)\n",
    "    data = re.sub(prog, ' ', data).lower()\n",
    "    prog = re.compile('[!\\\"#$%&\\'()*+\\,-/:;<=>?@[\\]^_`{|}~]', re.UNICODE)\n",
    "    cleaned = re.sub(prog, ' ', data)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we are not removing the stopwords. One reason is that often builtin stopwords lists for English language contain the word 'no', 'nor','not' etc. If removed it can change the sentiment e.g 'Food is not good' and 'Food is good' both will become 'Food good'. It is therefore decided not to remove stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to decode and print output labels and polarity for a review\n",
    "def output_to_labels(output):\n",
    "    '''\n",
    "     Description: Converts predicted output for a review into labels and polarity\n",
    "     Arguments: output a numpy array\n",
    "                \n",
    "    '''\n",
    "    labels = ['SERVICE#GENERAL', 'RESTAURANT#PRICES',\n",
    "       'RESTAURANT#MISCELLANEOUS', 'RESTAURANT#GENERAL', 'LOCATION#GENERAL',\n",
    "       'FOOD#STYLE_OPTIONS', 'FOOD#QUALITY', 'FOOD#PRICES',\n",
    "       'DRINKS#STYLE_OPTIONS', 'DRINKS#QUALITY', 'DRINKS#PRICES',\n",
    "       'AMBIENCE#GENERAL']\n",
    "    for index in range(len(labels)):\n",
    "        value = output[0,index]\n",
    "        if(value == 1):\n",
    "            print(labels[index],':',' ','positive')\n",
    "        elif(value == -1):\n",
    "            print(labels[index],':',' ','negative')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_training['TEXT'] = df_training['TEXT'].apply(clean_text_data)\n",
    "df_testing['TEXT'] = df_testing['TEXT'].apply(clean_text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>SERVICE#GENERAL</th>\n",
       "      <th>RESTAURANT#PRICES</th>\n",
       "      <th>RESTAURANT#MISCELLANEOUS</th>\n",
       "      <th>RESTAURANT#GENERAL</th>\n",
       "      <th>LOCATION#GENERAL</th>\n",
       "      <th>FOOD#STYLE_OPTIONS</th>\n",
       "      <th>FOOD#QUALITY</th>\n",
       "      <th>FOOD#PRICES</th>\n",
       "      <th>DRINKS#STYLE_OPTIONS</th>\n",
       "      <th>DRINKS#QUALITY</th>\n",
       "      <th>DRINKS#PRICES</th>\n",
       "      <th>AMBIENCE#GENERAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yum    serves really good sushi    not the b...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no comparison   – i can t say enough about t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>snotty attitude   – we were treated very rud...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good food    – we love breakfast food    thi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>overrated   – i was highly disappointed in t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TEXT  SERVICE#GENERAL  \\\n",
       "0    yum    serves really good sushi    not the b...              0.0   \n",
       "1    no comparison   – i can t say enough about t...              1.0   \n",
       "2    snotty attitude   – we were treated very rud...             -1.0   \n",
       "3    good food    – we love breakfast food    thi...              1.0   \n",
       "4    overrated   – i was highly disappointed in t...              0.0   \n",
       "\n",
       "   RESTAURANT#PRICES  RESTAURANT#MISCELLANEOUS  RESTAURANT#GENERAL  \\\n",
       "0                0.0                       0.0                   1   \n",
       "1                0.0                       0.0                   1   \n",
       "2                0.0                       0.0                  -1   \n",
       "3                0.0                       0.0                   1   \n",
       "4               -1.0                       0.0                  -1   \n",
       "\n",
       "   LOCATION#GENERAL  FOOD#STYLE_OPTIONS  FOOD#QUALITY  FOOD#PRICES  \\\n",
       "0               0.0                 0.0           1.0          0.0   \n",
       "1               0.0                 0.0           1.0          0.0   \n",
       "2               0.0                 0.0           0.0          0.0   \n",
       "3               0.0                 0.0           1.0          0.0   \n",
       "4               0.0                -1.0          -1.0          0.0   \n",
       "\n",
       "   DRINKS#STYLE_OPTIONS  DRINKS#QUALITY  DRINKS#PRICES  AMBIENCE#GENERAL  \n",
       "0                   0.0             0.0            0.0               0.0  \n",
       "1                   0.0             0.0            0.0               0.0  \n",
       "2                   0.0             0.0            0.0               0.0  \n",
       "3                   0.0             0.0            0.0               0.0  \n",
       "4                   0.0             0.0            0.0               1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to do Feature Scaling\n",
    "def standardize_features(X_train,X_test, standardize=True):\n",
    "    \"\"\"\n",
    "    Returns standardized features\n",
    "    :param X_train: Training data to be standardized\n",
    "    :param X_test : Testing data to be standardized\n",
    "    :param standardize : A flag to indicate if we need data standardized\n",
    "    :return: X_train_std,X_test_std: Standardized training and testing data\n",
    "    \"\"\"\n",
    "    standardizer = StandardScaler()\n",
    "    X_train_std = X_train\n",
    "    X_test_std = X_test\n",
    "\n",
    "    if(standardize):\n",
    "        X_train_std = standardizer.fit_transform(X_train)\n",
    "        X_test_std = standardizer.transform(X_test)\n",
    "\n",
    "    return X_train_std,X_test_std, standardizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Prepare training and testing datasets\n",
    "X_train = df_training['TEXT']\n",
    "y_train = df_training.drop('TEXT',axis=1)\n",
    "\n",
    "X_test = df_testing['TEXT']\n",
    "y_test = df_testing.drop('TEXT',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Evaluation metrics for Multilabel Multiclass Classifiers ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to measure the performance of a multilabel multiclass classifier we can use F1 score. F1 score is the weighted average of precision and recall. For multilabel multioutput case the F1(microaveraged) and F1(macroaveraged) can be given by the following equations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/f1_score_multiple.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference:** <a href=\"http://machinelearning.wustl.edu/mlpapers/paper_files/icml2004_GaoWLC04.pdf\" target=_blank> A MFoM Learning Approach to Robust Multiclass Multi-Label Text Categorization</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As scikit-learn does not provide a built-in metrics we have to write a custom function to implement the above. The R is recall and P denotes precision for a class i in N labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Function to compute F1_Score (microaveraged)\n",
    "def compute_f1_score_micro(y_true, y_predicted):\n",
    "    '''\n",
    "    Description : Computes and returns F1 score microaveraged\n",
    "    Arguments:\n",
    "                 y_true:       True value\n",
    "                 y_ predicted: Predicted values \n",
    "    '''\n",
    "    TP,FP,TN,FN=0,0,0,0\n",
    "    TP_sum,FP_sum,TN_sum,FN_sum=0,0,0,0\n",
    "    for column_index in range(y_true.shape[1]):\n",
    "        true_values = np.array(y_true)[:,column_index]\n",
    "        predicted_values = np.array(y_predicted)[:,column_index]\n",
    "        for index in range(len(true_values)):\n",
    "            if(true_values[index]==predicted_values[index]==1):\n",
    "                TP += 1\n",
    "            elif(true_values[index]==predicted_values[index]==-1):\n",
    "                TP += 1\n",
    "            elif(true_values[index]==0 and predicted_values[index]!=0):\n",
    "                FP += 1\n",
    "            elif(true_values[index]!=0 and predicted_values[index]==0):\n",
    "                FN += 1\n",
    "            else:\n",
    "                TN += 1   \n",
    "        TP_sum = TP_sum + TP\n",
    "        FP_sum = FP_sum + FP\n",
    "        TN_sum = TN_sum + TN\n",
    "        FN_sum = FN_sum + FN\n",
    "    return ((2*TP_sum)/(FP_sum+FN_sum+(2*TP_sum)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to evaluate the sentiment polarity of the aspects. In order to evaluate the polarity we are using the same strategy as given in\n",
    "<a href=\"http://galanisd.github.io/Papers/2015SemEval_ABSA_overview.pdf\" target=\"_blank\"> SemEval-2015 Task 12: Aspect Based Sentiment Analysis </a>.\n",
    "<br/> Which defines the _polarity accuracy as the number of correctly predicted polarity labels of aspect categories, divided by the total number of aspect categories.**Note that we are not using neutral sentiment. The score is only for positive or negative sentiments**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Function to compute accuracy of polarity prediction\n",
    "def compute_polarity_accuracy_score(y_true, y_predicted):\n",
    "    '''\n",
    "    Description : Compute the accuracy of the polarity\n",
    "    Arguments : \n",
    "                   y_true :   True value\n",
    "                   y_ predicted: Predicted values \n",
    "    '''\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for column_index in range(y_true.shape[1]):\n",
    "        true_values = np.array(y_true)[:,column_index]\n",
    "        predicted_values = np.array(y_predicted)[:,column_index]\n",
    "        for index in range(len(true_values)):\n",
    "            if(true_values[index]==predicted_values[index]==1):\n",
    "                correct += 1\n",
    "                total += 1\n",
    "            elif(true_values[index]==predicted_values[index]==-1):\n",
    "                correct += 1\n",
    "                total += 1\n",
    "            elif(true_values[index]==1 and predicted_values[index]==-1):\n",
    "                total += 1\n",
    "            elif(true_values[index]==-1 and predicted_values[index]==1):\n",
    "                total += 1\n",
    "            else:\n",
    "                pass\n",
    "    return (correct/total)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make scoring function\n",
    "f1_scorer = make_scorer(compute_f1_score_micro, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Baseline Classifer (RandomForest with CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator Parameters are: {'clf__estimator__n_estimators': 350} 0.718798696709\n"
     ]
    }
   ],
   "source": [
    "#RandomForest Classifier\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(ngram_range=(1,2))),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier(max_depth=3,class_weight='balanced')))])\n",
    "#RandomForest specific parameters\n",
    "parameters = {\n",
    "'clf__estimator__n_estimators': [100,300,350]\n",
    "}\n",
    "#Find the optimal parameters for RandomForest\n",
    "model_parameter_selection = GridSearchCV(pipeline,param_grid=parameters,cv=5,scoring = f1_scorer)\n",
    "model_parameter_selection.fit(X_train, y_train)\n",
    "print(\"Best Estimator Parameters are:\",model_parameter_selection.best_params_, model_parameter_selection.best_score_)\n",
    "y_predicted = model_parameter_selection.predict(X_test)\n",
    "f1_micro=compute_f1_score_micro(y_test,y_predicted)\n",
    "polarity_accuracy = compute_polarity_accuracy_score(y_test,y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score for classifier:  0.7170465807730426\n",
      "Accuracy Score for sentiment polarity:  0.8296943231441049\n"
     ]
    }
   ],
   "source": [
    "print('F1-Score for classifier: ',f1_micro)\n",
    "print('Accuracy Score for sentiment polarity: ',polarity_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to find aspects and sentiment polarity given a review\n",
    "def analyze_review(classifier, review_text):\n",
    "    '''\n",
    "    Description : Detects Aspects and finds the polarities given review text\n",
    "    Arguments : \n",
    "                review_text : A string with review sentence/sentences\n",
    "                classifier: A model used to predict the aspects and polarities\n",
    "    '''\n",
    "    dictionary = {'review':clean_text_data(review_text)}\n",
    "    df_input=pd.DataFrame(dictionary,index=np.arange(len(dictionary.keys())))\n",
    "    output = classifier.predict(df_input['review'])\n",
    "    output_to_labels(output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESTAURANT#GENERAL :   positive\n",
      "FOOD#QUALITY :   positive\n"
     ]
    }
   ],
   "source": [
    "classifier = model_parameter_selection\n",
    "review_text = \"worst service i ever had  a group of   of us went there for sunday brunch and sat outside    everyone that sat in the back outside agreed that it was the worst service we had ever received    our waiter was non existent and after our food finally arrived over an hour after we ordered  we were not given any water or utensils    i complained to the manager  but he was not even apologetic    i will never return again\"\n",
    "analyze_review(classifier,\"The food was terrible as far as I am concerned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Embeddings are dense low dimensional representation of words. Word Embeddings convert words from a vocabulary into vectors of real numbers. Word Embeddings have been used in many Sentiment Analysis tasks and have been found to be quite effective. An example model is given in <a href=\"http://www.cs.ubc.ca/~rjoty/paper/emnlp-paper-drnn-cr.pdf\" target=_blank>Fine-grained Opinion Mining with Recurrent Neural Networks and Word Embeddings</a>. Word Embeddings or Vector Space Models (VSM) place words with semantic similarity nearby in the vector space.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we can use Word Embeddings created from generic corpuses. It is a good idea to generate a domain specific Word Embeddings model as shown in <a href=\"http://nlp.stanford.edu/pubs/hamilton2016inducing.pdf\">Inducing Domain-Specific Sentiment Lexicons from Unlabeled Corpora</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yelp has made public a huge dataset as part of its data challenge program. We used the scripts available at <a href=\"https://github.com/titipata/yelp_dataset_challenge\" target=_blank>Yelp dataset challenge scripts</a> to create Word Embeddings. The scripts do not work with the latest version of Tensorflow (r0.12) and Python 3 so we had to modify them slightly. The updated scripts are available at <a href=\"https://github.com/umairacheema/yelp_dataset_challenge/tree/hotfix/python3x\"target=_blank>Yelp Util for Tensorflow r0.12</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The jupyter notebook to build domain specific word embedding for Restaurants is given in the aforementioned github repository as well. There are **21,892** restaurants and **9,90,627** reviews in the corpus used to build domain specific WordEmbeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#The following code will not run in notebook as it requires the yelword2vec\n",
    "#created using code in \n",
    "#https://github.com/umairacheema/yelp_dataset_challenge/blob/hotfix/python3x/examples/domain_specific_word_embeddings.ipynb\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "w2vmodel = Word2Vec.load_word2vec_format('data/yelpword2vec', binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to compute vectorized representation of a single review\n",
    "#Review should be a list of words\n",
    "def vectorize_review_w2v(w2vmodel,review,size=100):\n",
    "    '''\n",
    "    Description : Given word2vec model and review compute average\n",
    "                  feature vector\n",
    "    Arguments :\n",
    "                 w2vmodel : Trained word2vec model\n",
    "                 review : A single review as a list of words\n",
    "    '''\n",
    "    #Clean the review data\n",
    "    review = clean_text_data(review)\n",
    "    #Convert review into a list of words.\n",
    "    text = review.split()\n",
    "    word_count = 0\n",
    "    vector = np.zeros(size).reshape((1, size))\n",
    "    w2vmodel_words = set(w2vmodel.index2word)\n",
    "    for word in text:\n",
    "        if word in w2vmodel_words:\n",
    "            #vector += w2vmodel[word].reshape((1,size))\n",
    "            vector = np.add(vector,w2vmodel[word])\n",
    "            word_count += 1\n",
    "    if word_count>0:\n",
    "        vector = vector/word_count\n",
    "    return vector\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to vectorize multiple reviews using word2vec\n",
    "def vectorize_reviews_w2v(w2vmodel,reviews,size=100):\n",
    "    '''\n",
    "    Description: Given a Pandas Series with reviews, compute dense\n",
    "                 vectorized representation using Word2Vec\n",
    "    Arguments :\n",
    "                w2vmodel : Trained word2vec model\n",
    "                reviews: A Pandas series with all the reviews.\n",
    "    '''\n",
    "    #default value of 100 used by yelp_util\n",
    "    #Initialize a numpy array to store  feature vector for\n",
    "    #all reviews\n",
    "    vectorized_features = np.zeros((len(reviews),size),dtype='float32')\n",
    "    #Initialize a vector index\n",
    "    index = 0\n",
    "    for review in reviews:\n",
    "        vectorized_features[index] = vectorize_review_w2v(w2vmodel,review,size)\n",
    "        index += 1\n",
    "    return vectorized_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Convert training and testing features \n",
    "# into feature vectors\n",
    "training_features = vectorize_reviews_w2v(w2vmodel,X_train,size=100)\n",
    "testing_features = vectorize_reviews_w2v(w2vmodel,X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As RandomForest does not require Standardized features we are not doing feature scaling or standardization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Random Forest with Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator Parameters are: {'estimator__n_estimators': 350} 0.697912552508\n"
     ]
    }
   ],
   "source": [
    "rfclf = MultiOutputClassifier(RandomForestClassifier(max_depth=3,class_weight='balanced'))\n",
    "#RandomForest specific parameters\n",
    "parameters = {\n",
    "'estimator__n_estimators': [100,300,350]\n",
    "}\n",
    "#Find the optimal parameters for RandomForest\n",
    "rf_parameter_selection = GridSearchCV(rfclf,param_grid=parameters,cv=5,scoring = f1_scorer)\n",
    "rf_parameter_selection.fit(training_features, y_train)\n",
    "print(\"Best Estimator Parameters are:\",rf_parameter_selection.best_params_, rf_parameter_selection.best_score_)\n",
    "rf_y_predicted = rf_parameter_selection.predict(testing_features)\n",
    "rf_f1_micro=compute_f1_score_micro(y_test,rf_y_predicted)\n",
    "rf_polarity_accuracy = compute_polarity_accuracy_score(y_test,rf_y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7196082605918671 0.8879668049792531\n"
     ]
    }
   ],
   "source": [
    "print(rf_f1_micro,rf_polarity_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Function to test on an unseen short review\n",
    "def classify_short_review(classifier,w2vmodel,size=100):\n",
    "    review_text = \"I love the food. The service was terrible. I hated the whole thing.\"\n",
    "    cleaned = clean_text_data(review_text)\n",
    "    predicted = classifier.predict(vectorize_review_w2v(w2vmodel,cleaned,size))\n",
    "    print(output_to_labels(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESTAURANT#GENERAL :   negative\n",
      "FOOD#QUALITY :   negative\n"
     ]
    }
   ],
   "source": [
    "output_to_labels(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Support Vector Machines with WordEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator Parameters are: {'estimator__C': 10, 'estimator__gamma': 0.001} 0.733305052885\n",
      "SVM F1 Score: 0.7398895027624309\n",
      "SVM Polarity Accuracy: 0.9130434782608695\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svmclf = MultiOutputClassifier(SVC(kernel='rbf'))\n",
    "#Support Vector Machine specific parameters\n",
    "parameters = {\n",
    "'estimator__gamma': [0.0001,0.001,0.01,0.1],\n",
    "'estimator__C':[0.1,1,10,100]\n",
    "}\n",
    "#As an additional step we need to standardize the features\n",
    "training_features_std, testing_features_std, standardizer = standardize_features(training_features,testing_features) \n",
    "#Find the optimal parameters for Support Vector Machine Classifier\n",
    "svm_parameter_selection = GridSearchCV(svmclf,param_grid=parameters,cv=5,scoring = f1_scorer)\n",
    "svm_parameter_selection.fit(training_features_std, y_train)\n",
    "print(\"Best Estimator Parameters are:\",svm_parameter_selection.best_params_, svm_parameter_selection.best_score_)\n",
    "svm_y_predicted = svm_parameter_selection.predict(testing_features_std)\n",
    "svm_f1_micro=compute_f1_score_micro(y_test,svm_y_predicted)\n",
    "svm_polarity_accuracy = compute_polarity_accuracy_score(y_test,svm_y_predicted)\n",
    "print('SVM F1 Score:',svm_f1_micro)\n",
    "print('SVM Polarity Accuracy:',svm_polarity_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It is important to note that even with fine tuned Support Vector Machines the test accuracy is not very high. This could mean that we need to improve our WordEmbeddings model. Previously we used a feature size of 300 as that was hardcoded in the yelp util. We also did not add the SemEval datasets while training the word2vec model. We now need to train a new Word2Vector model and train it on the corpus. We shall also try Continuous Bag of Words (CBOW) as well as Skip-n gram based models.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Support Vector Machines with Bigger Feature Size and CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read the Yelp restaurants reviews data\n",
    "df_yelp_restaurant_reviews = pd.read_pickle('data/restaurant_reviews.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Combine the review data with the Semantic Evaluation data\n",
    "yelp_reviews_text = df_yelp_restaurant_reviews.text\n",
    "combined_reviews_text = pd.concat([yelp_reviews_text,X_train],axis=0)\n",
    "yelp_reviews_text = yelp_reviews_text.to_string(header=False,index=False)\n",
    "yelp_reviews_text = clean_text_data(yelp_reviews_text)\n",
    "#Save all reviews in a text file\n",
    "file = open('data/yelp_semeval_reviews.txt', 'w')\n",
    "file.write(yelp_reviews_text)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from gensim.models.word2vec import LineSentence\n",
    "#Convert it into a format that word2vec can understand\n",
    "linesentences = LineSentence('data/yelp_semeval_reviews.txt')\n",
    "#Build the model with higher number of features\n",
    "n_dims = 500\n",
    "cbow_model = Word2Vec(linesentences,size=n_dims,workers=multiprocessing.cpu_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Convert training and testing features \n",
    "# into feature vectors\n",
    "training_features_cbow = vectorize_reviews_w2v(cbow_model,X_train,size=n_dims)\n",
    "testing_features_cbow = vectorize_reviews_w2v(cbow_model,X_test,size=n_dims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator Parameters are: {'estimator__C': 10, 'estimator__gamma': 0.0001} 0.719240597991\n",
      "SVM F1 Score: 0.7345273180684652\n",
      "SVM Polarity Accuracy: 0.8938053097345132\n"
     ]
    }
   ],
   "source": [
    "svmclf = MultiOutputClassifier(SVC(kernel='rbf'))\n",
    "#Support Vector Machine specific parameters\n",
    "parameters = {\n",
    "'estimator__gamma': [0.0001,0.001,0.01,0.1],\n",
    "'estimator__C':[0.1,1,10,100]\n",
    "}\n",
    "#As an additional step we need to standardize the features\n",
    "training_features_std, testing_features_std, standardizer = standardize_features(training_features_cbow,testing_features_cbow) \n",
    "#Find the optimal parameters for Support Vector Machine Classifier\n",
    "svm_parameter_selection = GridSearchCV(svmclf,param_grid=parameters,cv=5,scoring = f1_scorer)\n",
    "svm_parameter_selection.fit(training_features_std, y_train)\n",
    "print(\"Best Estimator Parameters are:\",svm_parameter_selection.best_params_, svm_parameter_selection.best_score_)\n",
    "svm_y_predicted = svm_parameter_selection.predict(testing_features_std)\n",
    "svm_f1_micro=compute_f1_score_micro(y_test,svm_y_predicted)\n",
    "svm_polarity_accuracy = compute_polarity_accuracy_score(y_test,svm_y_predicted)\n",
    "print('SVM F1 Score:',svm_f1_micro)\n",
    "print('SVM Polarity Accuracy:',svm_polarity_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SERVICE#GENERAL :   negative\n",
      "RESTAURANT#GENERAL :   negative\n",
      "FOOD#QUALITY :   negative\n"
     ]
    }
   ],
   "source": [
    "review_text =\"I did not like this place.The staff was good.\"\n",
    "review_text = clean_text_data(review_text)\n",
    "feature = vectorize_review_w2v(cbow_model,review_text,size=n_dims)\n",
    "feature_std = standardizer.transform(feature)\n",
    "predicted= svm_parameter_selection.predict(feature_std)\n",
    "output_to_labels(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0304029   0.07559045 -0.06514373 ..., -0.04291529 -0.20947297\n",
      "  -0.04910846]\n",
      " [-0.19939972  0.26889768  0.25863898 ...,  0.13018645 -0.16195723\n",
      "   0.00127879]\n",
      " [-0.16938011 -0.06242532 -0.04314443 ..., -0.00968929 -0.28984979\n",
      "   0.1121956 ]\n",
      " ..., \n",
      " [-0.18494466  0.20268759  0.17381716 ...,  0.02723992 -0.21639413\n",
      "   0.0179843 ]\n",
      " [-0.22209762  0.23866831  0.28071001 ...,  0.16685204 -0.08933052\n",
      "  -0.14263883]\n",
      " [-0.19387409  0.23260443  0.1264381  ...,  0.191836   -0.24203971\n",
      "  -0.05207661]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X must be non-negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-248-6cd7b13ef54d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiOutputClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_features_cbow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_features_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mlr_y_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_features_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mlr_f1_micro\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_f1_score_micro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr_y_predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.5/site-packages/sklearn/multioutput.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         self.estimators_ = Parallel(n_jobs=self.n_jobs)(delayed(_fit_estimator)(\n\u001b[0;32m---> 87\u001b[0;31m             self.estimator, X, y[:, i], sample_weight) for i in range(y.shape[1]))\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.5/site-packages/sklearn/multioutput.py\u001b[0m in \u001b[0;36m_fit_estimator\u001b[0;34m(estimator, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.5/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    585\u001b[0m         self.feature_count_ = np.zeros((n_effective_classes, n_features),\n\u001b[1;32m    586\u001b[0m                                        dtype=np.float64)\n\u001b[0;32m--> 587\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_class_log_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_prior\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_prior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.5/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input X must be non-negative\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input X must be non-negative"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "lr = MultiOutputClassifier(MultinomialNB())\n",
    "print(training_features_cbow)\n",
    "lr.fit(training_features_std, y_train)\n",
    "lr_y_predicted = lr.predict(testing_features_std)\n",
    "lr_f1_micro=compute_f1_score_micro(y_test,lr_y_predicted)\n",
    "lr_polarity_accuracy = compute_polarity_accuracy_score(y_test,lr_y_predicted)\n",
    "print('SVM F1 Score:',lr_f1_micro)\n",
    "print('SVM Polarity Accuracy:',lr_polarity_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Support Vector Machines with CBOW and TfIdfVectorizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) Support Vector Machines with Skip gram, TfIdfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10) Support Vector Machines with gensim Phrase model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
