{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the Semeval data and return a dataframe for multi-label multi-output classification\n",
    "def read_semeval_data(filename):\n",
    "    '''\n",
    "    Description: reads Semantic Evaluation XML dataset and converts into a \n",
    "                 dataframe\n",
    "    Arguments:\n",
    "                 filename: string with file path (including filename)\n",
    "    Returns :    pandas data frame\n",
    "    Important:   this function only puts positive and neutral reviews in dataframe                          \n",
    "    '''\n",
    "    f = open(filename, 'r')\n",
    "    raw_training_data = f.read()\n",
    "    xmldoc = BeautifulSoup(raw_training_data,'lxml-xml')\n",
    "    sentences = xmldoc.Reviews.find_all('sentences')\n",
    "    opinions = xmldoc.Reviews.find_all('Opinions')\n",
    "    reviews = []\n",
    "    for i in range(0,len(sentences)):\n",
    "        record = {}\n",
    "        entity_aspect_pairs = opinions[i].find_all('Opinion')\n",
    "        for ea_pair in entity_aspect_pairs:\n",
    "            ea = ea_pair.attrs['category']\n",
    "            polarity = ea_pair.attrs['polarity']\n",
    "            if(polarity == 'positive'):\n",
    "                record[ea] = 1\n",
    "            elif(polarity == 'negative'):\n",
    "                record[ea] = -1\n",
    "            else:\n",
    "                record[ea] = 0           \n",
    "        record['TEXT'] = sentences[i].get_text()\n",
    "        reviews.append(record)\n",
    "    #Create a dataframe\n",
    "    df=pd.DataFrame(reviews)\n",
    "    #Change order of the columns so that text appears first\n",
    "    cols = df.columns.tolist()\n",
    "    cols.sort()\n",
    "    cols.reverse()\n",
    "    df = df[cols]\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the Semeval data and return a dataframe for multi-label only\n",
    "def read_semeval_data_multilabel(filename):\n",
    "    '''\n",
    "    Description: reads Semantic Evaluation XML dataset and converts into a \n",
    "                 dataframe with Multilabel data\n",
    "    Arguments:\n",
    "                 filename: string with file path (including filename)\n",
    "    Returns :    pandas data frame\n",
    "    Important:   this function only puts positive and neutral reviews in dataframe                          \n",
    "    '''\n",
    "    possible_labels=['SERVICE#GENERAL#POSITIVE', 'SERVICE#GENERAL#NEGATIVE', 'RESTAURANT#PRICES#POSITIVE', \n",
    "                     'RESTAURANT#PRICES#NEGATIVE', 'RESTAURANT#MISCELLANEOUS#POSITIVE', \n",
    "                     'RESTAURANT#MISCELLANEOUS#NEGATIVE', 'RESTAURANT#GENERAL#POSITIVE', 'RESTAURANT#GENERAL#NEGATIVE',\n",
    "                     'LOCATION#GENERAL#POSITIVE', 'LOCATION#GENERAL#NEGATIVE', 'FOOD#STYLE_OPTIONS#POSITIVE', \n",
    "                     'FOOD#STYLE_OPTIONS#NEGATIVE', 'FOOD#QUALITY#POSITIVE', 'FOOD#QUALITY#NEGATIVE', \n",
    "                     'FOOD#PRICES#POSITIVE', 'FOOD#PRICES#NEGATIVE', 'DRINKS#STYLE_OPTIONS#POSITIVE', \n",
    "                     'DRINKS#STYLE_OPTIONS#NEGATIVE', 'DRINKS#QUALITY#POSITIVE', 'DRINKS#QUALITY#NEGATIVE', \n",
    "                     'DRINKS#PRICES#POSITIVE', 'DRINKS#PRICES#NEGATIVE', 'AMBIENCE#GENERAL#POSITIVE', \n",
    "                     'AMBIENCE#GENERAL#NEGATIVE']\n",
    "    f = open(filename, 'r')\n",
    "    raw_training_data = f.read()\n",
    "    xmldoc = BeautifulSoup(raw_training_data,'lxml-xml')\n",
    "    sentences = xmldoc.Reviews.find_all('sentences')\n",
    "    opinions = xmldoc.Reviews.find_all('Opinions')\n",
    "    reviews = []\n",
    "    for i in range(0,len(sentences)):\n",
    "        record = {}\n",
    "        entity_aspect_pairs = opinions[i].find_all('Opinion')\n",
    "        for ea_pair in entity_aspect_pairs:\n",
    "            ea = ea_pair.attrs['category']\n",
    "            polarity = ea_pair.attrs['polarity']\n",
    "            if(polarity == 'positive'):\n",
    "                record[ea+'#POSITIVE'] = 1\n",
    "            elif(polarity == 'negative'):\n",
    "                record[ea+'#NEGATIVE'] = 1\n",
    "            else:\n",
    "                record[ea+'#POSITIVE'] = 0\n",
    "                record[ea+'#NEGATIVE'] = 0\n",
    "        record['TEXT'] = sentences[i].get_text()\n",
    "        reviews.append(record)\n",
    "    #Create a dataframe\n",
    "    df=pd.DataFrame(reviews)\n",
    "    #Change order of the columns so that text appears first\n",
    "    cols = df.columns.tolist()\n",
    "    for label in possible_labels:\n",
    "        if(label not in cols):\n",
    "            df[label] = 0\n",
    "    cols = df.columns.tolist()\n",
    "    cols.sort()\n",
    "    cols.reverse()\n",
    "    df = df[cols]\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "entity_labels = ['Food','Drinks','Service','Ambience','Location','Restaurant']\n",
    "<br/>attributes_labels = ['General','Prices','Quality','Style&Options','Miscellaneous']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Possible Combinations of Entities and Attributes #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/entity_attributes_combinations.jpg' style='width:50;height:50'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>SERVICE#GENERAL</th>\n",
       "      <th>RESTAURANT#PRICES</th>\n",
       "      <th>RESTAURANT#MISCELLANEOUS</th>\n",
       "      <th>RESTAURANT#GENERAL</th>\n",
       "      <th>LOCATION#GENERAL</th>\n",
       "      <th>FOOD#STYLE_OPTIONS</th>\n",
       "      <th>FOOD#QUALITY</th>\n",
       "      <th>FOOD#PRICES</th>\n",
       "      <th>DRINKS#STYLE_OPTIONS</th>\n",
       "      <th>DRINKS#QUALITY</th>\n",
       "      <th>DRINKS#PRICES</th>\n",
       "      <th>AMBIENCE#GENERAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nYum!\\n\\n\\nServes really good sushi.\\n\\n\\nN...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nNo Comparison\\n\\n\\n– I can't say enough ab...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\nSnotty Attitude\\n\\n\\n– We were treated ver...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\nGood food!\\n\\n\\n– We love breakfast food.\\...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\nOverrated\\n\\n\\n– I was highly disappointed...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TEXT  SERVICE#GENERAL  \\\n",
       "0  \\n\\nYum!\\n\\n\\nServes really good sushi.\\n\\n\\nN...              0.0   \n",
       "1  \\n\\nNo Comparison\\n\\n\\n– I can't say enough ab...              1.0   \n",
       "2  \\n\\nSnotty Attitude\\n\\n\\n– We were treated ver...             -1.0   \n",
       "3  \\n\\nGood food!\\n\\n\\n– We love breakfast food.\\...              1.0   \n",
       "4  \\n\\nOverrated\\n\\n\\n– I was highly disappointed...              0.0   \n",
       "\n",
       "   RESTAURANT#PRICES  RESTAURANT#MISCELLANEOUS  RESTAURANT#GENERAL  \\\n",
       "0                0.0                       0.0                   1   \n",
       "1                0.0                       0.0                   1   \n",
       "2                0.0                       0.0                  -1   \n",
       "3                0.0                       0.0                   1   \n",
       "4               -1.0                       0.0                  -1   \n",
       "\n",
       "   LOCATION#GENERAL  FOOD#STYLE_OPTIONS  FOOD#QUALITY  FOOD#PRICES  \\\n",
       "0               0.0                 0.0           1.0          0.0   \n",
       "1               0.0                 0.0           1.0          0.0   \n",
       "2               0.0                 0.0           0.0          0.0   \n",
       "3               0.0                 0.0           1.0          0.0   \n",
       "4               0.0                -1.0          -1.0          0.0   \n",
       "\n",
       "   DRINKS#STYLE_OPTIONS  DRINKS#QUALITY  DRINKS#PRICES  AMBIENCE#GENERAL  \n",
       "0                   0.0             0.0            0.0               0.0  \n",
       "1                   0.0             0.0            0.0               0.0  \n",
       "2                   0.0             0.0            0.0               0.0  \n",
       "3                   0.0             0.0            0.0               0.0  \n",
       "4                   0.0             0.0            0.0               1.0  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training = read_semeval_data('data/train.xml')\n",
    "df_testing = read_semeval_data('data/test.xml')\n",
    "df_testing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataframe above a +1 indicates a positive polarity and -1 indicates negative polarity whereas 0 means that this aspect is not found or found to be neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read multilabel data only\n",
    "df_training_multilabel = read_semeval_data_multilabel('data/train.xml')\n",
    "df_testing_multilabel = read_semeval_data_multilabel('data/test.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>SERVICE#GENERAL#POSITIVE</th>\n",
       "      <th>SERVICE#GENERAL#NEGATIVE</th>\n",
       "      <th>RESTAURANT#PRICES#POSITIVE</th>\n",
       "      <th>RESTAURANT#PRICES#NEGATIVE</th>\n",
       "      <th>RESTAURANT#MISCELLANEOUS#POSITIVE</th>\n",
       "      <th>RESTAURANT#MISCELLANEOUS#NEGATIVE</th>\n",
       "      <th>RESTAURANT#GENERAL#POSITIVE</th>\n",
       "      <th>RESTAURANT#GENERAL#NEGATIVE</th>\n",
       "      <th>LOCATION#GENERAL#POSITIVE</th>\n",
       "      <th>...</th>\n",
       "      <th>FOOD#PRICES#POSITIVE</th>\n",
       "      <th>FOOD#PRICES#NEGATIVE</th>\n",
       "      <th>DRINKS#STYLE_OPTIONS#POSITIVE</th>\n",
       "      <th>DRINKS#STYLE_OPTIONS#NEGATIVE</th>\n",
       "      <th>DRINKS#QUALITY#POSITIVE</th>\n",
       "      <th>DRINKS#QUALITY#NEGATIVE</th>\n",
       "      <th>DRINKS#PRICES#POSITIVE</th>\n",
       "      <th>DRINKS#PRICES#NEGATIVE</th>\n",
       "      <th>AMBIENCE#GENERAL#POSITIVE</th>\n",
       "      <th>AMBIENCE#GENERAL#NEGATIVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nYum!\\n\\n\\nServes really good sushi.\\n\\n\\nN...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nNo Comparison\\n\\n\\n– I can't say enough ab...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\nSnotty Attitude\\n\\n\\n– We were treated ver...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\nGood food!\\n\\n\\n– We love breakfast food.\\...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\nOverrated\\n\\n\\n– I was highly disappointed...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TEXT  \\\n",
       "0  \\n\\nYum!\\n\\n\\nServes really good sushi.\\n\\n\\nN...   \n",
       "1  \\n\\nNo Comparison\\n\\n\\n– I can't say enough ab...   \n",
       "2  \\n\\nSnotty Attitude\\n\\n\\n– We were treated ver...   \n",
       "3  \\n\\nGood food!\\n\\n\\n– We love breakfast food.\\...   \n",
       "4  \\n\\nOverrated\\n\\n\\n– I was highly disappointed...   \n",
       "\n",
       "   SERVICE#GENERAL#POSITIVE  SERVICE#GENERAL#NEGATIVE  \\\n",
       "0                       0.0                       0.0   \n",
       "1                       1.0                       0.0   \n",
       "2                       0.0                       1.0   \n",
       "3                       1.0                       0.0   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   RESTAURANT#PRICES#POSITIVE  RESTAURANT#PRICES#NEGATIVE  \\\n",
       "0                         0.0                         0.0   \n",
       "1                         0.0                         0.0   \n",
       "2                         0.0                         0.0   \n",
       "3                         0.0                         0.0   \n",
       "4                         0.0                         1.0   \n",
       "\n",
       "   RESTAURANT#MISCELLANEOUS#POSITIVE  RESTAURANT#MISCELLANEOUS#NEGATIVE  \\\n",
       "0                                0.0                                0.0   \n",
       "1                                0.0                                0.0   \n",
       "2                                0.0                                0.0   \n",
       "3                                0.0                                0.0   \n",
       "4                                0.0                                0.0   \n",
       "\n",
       "   RESTAURANT#GENERAL#POSITIVE  RESTAURANT#GENERAL#NEGATIVE  \\\n",
       "0                          1.0                          0.0   \n",
       "1                          1.0                          0.0   \n",
       "2                          0.0                          1.0   \n",
       "3                          1.0                          0.0   \n",
       "4                          0.0                          1.0   \n",
       "\n",
       "   LOCATION#GENERAL#POSITIVE            ...              FOOD#PRICES#POSITIVE  \\\n",
       "0                        0.0            ...                               0.0   \n",
       "1                        0.0            ...                               0.0   \n",
       "2                        0.0            ...                               0.0   \n",
       "3                        0.0            ...                               0.0   \n",
       "4                        0.0            ...                               0.0   \n",
       "\n",
       "   FOOD#PRICES#NEGATIVE  DRINKS#STYLE_OPTIONS#POSITIVE  \\\n",
       "0                   0.0                            0.0   \n",
       "1                   0.0                            0.0   \n",
       "2                   0.0                            0.0   \n",
       "3                   0.0                            0.0   \n",
       "4                   0.0                            0.0   \n",
       "\n",
       "   DRINKS#STYLE_OPTIONS#NEGATIVE  DRINKS#QUALITY#POSITIVE  \\\n",
       "0                            0.0                      0.0   \n",
       "1                            0.0                      0.0   \n",
       "2                            0.0                      0.0   \n",
       "3                            0.0                      0.0   \n",
       "4                            0.0                      0.0   \n",
       "\n",
       "   DRINKS#QUALITY#NEGATIVE  DRINKS#PRICES#POSITIVE  DRINKS#PRICES#NEGATIVE  \\\n",
       "0                        0                       0                     0.0   \n",
       "1                        0                       0                     0.0   \n",
       "2                        0                       0                     0.0   \n",
       "3                        0                       0                     0.0   \n",
       "4                        0                       0                     0.0   \n",
       "\n",
       "   AMBIENCE#GENERAL#POSITIVE  AMBIENCE#GENERAL#NEGATIVE  \n",
       "0                        0.0                        0.0  \n",
       "1                        0.0                        0.0  \n",
       "2                        0.0                        0.0  \n",
       "3                        0.0                        0.0  \n",
       "4                        1.0                        0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testing_multilabel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to clean the text data\n",
    "#Remove punctuations, newline characters and convert to lowercase.\n",
    "#Note that we are not removing dot to mark sentence boundary\n",
    "def clean_text_data(data):\n",
    "    '''\n",
    "    Description: Given text returns cleaned version\n",
    "    Arguments:\n",
    "                  data: string with raw review text\n",
    "    Returns  :\n",
    "                  cleaned: string with unwanted characters removed\n",
    "    '''\n",
    "    data = str(data).strip()\n",
    "    prog = re.compile('[\\t\\n\\r\\f\\v\\d\\']', re.UNICODE)\n",
    "    data = re.sub(prog, ' ', data).lower()\n",
    "    prog = re.compile('[!\\\"#$%&\\'()*+\\,-/:;<=>?@[\\]^_`{|}~]', re.UNICODE)\n",
    "    cleaned = re.sub(prog, ' ', data)\n",
    "    #Remove multiple whitespaces\n",
    "    cleaned = re.sub(' +',' ',cleaned)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we are not removing the stopwords. One reason is that often builtin stopwords lists for English language contain the word 'no', 'nor','not' etc. If removed it can change the sentiment e.g 'Food is not good' and 'Food is good' both will become 'Food good'. It is therefore decided not to remove stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_training['TEXT'] = df_training['TEXT'].apply(clean_text_data)\n",
    "df_testing['TEXT'] = df_testing['TEXT'].apply(clean_text_data)\n",
    "df_training_multilabel['TEXT'] = df_training_multilabel['TEXT'].apply(clean_text_data)\n",
    "df_testing_multilabel['TEXT'] = df_testing_multilabel['TEXT'].apply(clean_text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>SERVICE#GENERAL#POSITIVE</th>\n",
       "      <th>SERVICE#GENERAL#NEGATIVE</th>\n",
       "      <th>RESTAURANT#PRICES#POSITIVE</th>\n",
       "      <th>RESTAURANT#PRICES#NEGATIVE</th>\n",
       "      <th>RESTAURANT#MISCELLANEOUS#POSITIVE</th>\n",
       "      <th>RESTAURANT#MISCELLANEOUS#NEGATIVE</th>\n",
       "      <th>RESTAURANT#GENERAL#POSITIVE</th>\n",
       "      <th>RESTAURANT#GENERAL#NEGATIVE</th>\n",
       "      <th>LOCATION#GENERAL#POSITIVE</th>\n",
       "      <th>...</th>\n",
       "      <th>FOOD#PRICES#POSITIVE</th>\n",
       "      <th>FOOD#PRICES#NEGATIVE</th>\n",
       "      <th>DRINKS#STYLE_OPTIONS#POSITIVE</th>\n",
       "      <th>DRINKS#STYLE_OPTIONS#NEGATIVE</th>\n",
       "      <th>DRINKS#QUALITY#POSITIVE</th>\n",
       "      <th>DRINKS#QUALITY#NEGATIVE</th>\n",
       "      <th>DRINKS#PRICES#POSITIVE</th>\n",
       "      <th>DRINKS#PRICES#NEGATIVE</th>\n",
       "      <th>AMBIENCE#GENERAL#POSITIVE</th>\n",
       "      <th>AMBIENCE#GENERAL#NEGATIVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>sit in the balcony – not bad food was good an...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>late night dinning with exeptional food – i d...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>this place rocks – mercedes restaurant is so ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>insultingly overpriced mediocre service quali...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>much more than just a great view – i am excee...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 TEXT  \\\n",
       "85   sit in the balcony – not bad food was good an...   \n",
       "86   late night dinning with exeptional food – i d...   \n",
       "87   this place rocks – mercedes restaurant is so ...   \n",
       "88   insultingly overpriced mediocre service quali...   \n",
       "89   much more than just a great view – i am excee...   \n",
       "\n",
       "    SERVICE#GENERAL#POSITIVE  SERVICE#GENERAL#NEGATIVE  \\\n",
       "85                       0.0                       1.0   \n",
       "86                       1.0                       0.0   \n",
       "87                       1.0                       0.0   \n",
       "88                       0.0                       1.0   \n",
       "89                       1.0                       0.0   \n",
       "\n",
       "    RESTAURANT#PRICES#POSITIVE  RESTAURANT#PRICES#NEGATIVE  \\\n",
       "85                         0.0                         1.0   \n",
       "86                         1.0                         0.0   \n",
       "87                         1.0                         0.0   \n",
       "88                         0.0                         1.0   \n",
       "89                         0.0                         0.0   \n",
       "\n",
       "    RESTAURANT#MISCELLANEOUS#POSITIVE  RESTAURANT#MISCELLANEOUS#NEGATIVE  \\\n",
       "85                                1.0                                0.0   \n",
       "86                                0.0                                1.0   \n",
       "87                                0.0                                0.0   \n",
       "88                                0.0                                0.0   \n",
       "89                                0.0                                1.0   \n",
       "\n",
       "    RESTAURANT#GENERAL#POSITIVE  RESTAURANT#GENERAL#NEGATIVE  \\\n",
       "85                          0.0                          0.0   \n",
       "86                          1.0                          0.0   \n",
       "87                          1.0                          0.0   \n",
       "88                          0.0                          1.0   \n",
       "89                          1.0                          0.0   \n",
       "\n",
       "    LOCATION#GENERAL#POSITIVE            ...              \\\n",
       "85                        0.0            ...               \n",
       "86                        0.0            ...               \n",
       "87                        0.0            ...               \n",
       "88                        0.0            ...               \n",
       "89                        1.0            ...               \n",
       "\n",
       "    FOOD#PRICES#POSITIVE  FOOD#PRICES#NEGATIVE  DRINKS#STYLE_OPTIONS#POSITIVE  \\\n",
       "85                   0.0                   0.0                            0.0   \n",
       "86                   0.0                   0.0                            0.0   \n",
       "87                   0.0                   0.0                            0.0   \n",
       "88                   0.0                   1.0                            0.0   \n",
       "89                   0.0                   0.0                            0.0   \n",
       "\n",
       "    DRINKS#STYLE_OPTIONS#NEGATIVE  DRINKS#QUALITY#POSITIVE  \\\n",
       "85                            0.0                      0.0   \n",
       "86                            0.0                      0.0   \n",
       "87                            0.0                      1.0   \n",
       "88                            1.0                      0.0   \n",
       "89                            0.0                      0.0   \n",
       "\n",
       "    DRINKS#QUALITY#NEGATIVE  DRINKS#PRICES#POSITIVE  DRINKS#PRICES#NEGATIVE  \\\n",
       "85                        0                       0                     0.0   \n",
       "86                        0                       0                     0.0   \n",
       "87                        0                       0                     0.0   \n",
       "88                        0                       0                     1.0   \n",
       "89                        0                       0                     0.0   \n",
       "\n",
       "    AMBIENCE#GENERAL#POSITIVE  AMBIENCE#GENERAL#NEGATIVE  \n",
       "85                        1.0                        0.0  \n",
       "86                        1.0                        0.0  \n",
       "87                        1.0                        0.0  \n",
       "88                        1.0                        0.0  \n",
       "89                        0.0                        0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testing_multilabel.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to do Feature Scaling\n",
    "def standardize_features(X_train,X_test, standardize=True):\n",
    "    \"\"\"\n",
    "    Returns standardized features\n",
    "    :param X_train: Training data to be standardized\n",
    "    :param X_test : Testing data to be standardized\n",
    "    :param standardize : A flag to indicate if we need data standardized\n",
    "    :return: X_train_std,X_test_std: Standardized training and testing data\n",
    "    \"\"\"\n",
    "    standardizer = StandardScaler()\n",
    "    X_train_std = X_train\n",
    "    X_test_std = X_test\n",
    "\n",
    "    if(standardize):\n",
    "        X_train_std = standardizer.fit_transform(X_train)\n",
    "        X_test_std = standardizer.transform(X_test)\n",
    "\n",
    "    return X_train_std,X_test_std, standardizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Prepare training and testing datasets multilabel multioutput\n",
    "X_train = df_training['TEXT']\n",
    "y_train = df_training.drop('TEXT',axis=1)\n",
    "X_test = df_testing['TEXT']\n",
    "y_test = df_testing.drop('TEXT',axis=1)\n",
    "\n",
    "#Prepare training and testing datasets multilabel only\n",
    "X_train_multilabel = df_training_multilabel['TEXT']\n",
    "y_train_multliabel = df_training_multilabel.drop('TEXT',axis=1)\n",
    "X_test_multilabel = df_testing_multilabel['TEXT']\n",
    "y_test_multilabel = df_testing_multilabel.drop('TEXT',axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Evaluation metrics for Multilabel Multiclass Classifiers ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to measure the performance of a multilabel multiclass classifier we can use F1 score. F1 score is the weighted average of precision and recall. For multilabel multioutput case the F1(microaveraged) and F1(macroaveraged) can be given by the following equations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/f1_score_multiple.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference:** <a href=\"http://machinelearning.wustl.edu/mlpapers/paper_files/icml2004_GaoWLC04.pdf\" target=_blank> A MFoM Learning Approach to Robust Multiclass Multi-Label Text Categorization</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As scikit-learn does not provide a built-in metrics we have to write a custom function to implement the above. The R is recall and P denotes precision for a class i in N labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Function to compute F1_Score (microaveraged)\n",
    "def compute_f1_score_micro(y_true, y_predicted):\n",
    "    '''\n",
    "    Description : Computes and returns F1 score microaveraged\n",
    "    Arguments:\n",
    "                 y_true:       True value\n",
    "                 y_ predicted: Predicted values \n",
    "    '''\n",
    "    TP,FP,TN,FN=0,0,0,0\n",
    "    TP_sum,FP_sum,TN_sum,FN_sum=0,0,0,0\n",
    "    for column_index in range(y_true.shape[1]):\n",
    "        true_values = np.array(y_true)[:,column_index]\n",
    "        predicted_values = np.array(y_predicted)[:,column_index]\n",
    "        for index in range(len(true_values)):\n",
    "            if(true_values[index]==predicted_values[index]==1):\n",
    "                TP += 1\n",
    "            elif(true_values[index]==predicted_values[index]==-1):\n",
    "                TP += 1\n",
    "            elif(true_values[index]==0 and predicted_values[index]!=0):\n",
    "                FP += 1\n",
    "            elif(true_values[index]!=0 and predicted_values[index]==0):\n",
    "                FN += 1\n",
    "            else:\n",
    "                TN += 1   \n",
    "        TP_sum = TP_sum + TP\n",
    "        FP_sum = FP_sum + FP\n",
    "        TN_sum = TN_sum + TN\n",
    "        FN_sum = FN_sum + FN\n",
    "    return ((2*TP_sum)/(FP_sum+FN_sum+(2*TP_sum)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to evaluate the sentiment polarity of the aspects. In order to evaluate the polarity we are using the same strategy as given in\n",
    "<a href=\"http://galanisd.github.io/Papers/2015SemEval_ABSA_overview.pdf\" target=\"_blank\"> SemEval-2015 Task 12: Aspect Based Sentiment Analysis </a>.\n",
    "<br/> Which defines the _polarity accuracy as the number of correctly predicted polarity labels of aspect categories, divided by the total number of aspect categories.**Note that we are not using neutral sentiment. The score is only for positive or negative sentiments**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Function to compute accuracy of polarity prediction\n",
    "def compute_polarity_accuracy_score(y_true, y_predicted):\n",
    "    '''\n",
    "    Description : Compute the accuracy of the polarity\n",
    "    Arguments : \n",
    "                   y_true :   True value\n",
    "                   y_ predicted: Predicted values \n",
    "    '''\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for column_index in range(y_true.shape[1]):\n",
    "        true_values = np.array(y_true)[:,column_index]\n",
    "        predicted_values = np.array(y_predicted)[:,column_index]\n",
    "        for index in range(len(true_values)):\n",
    "            if(true_values[index]==predicted_values[index]==1):\n",
    "                correct += 1\n",
    "                total += 1\n",
    "            elif(true_values[index]==predicted_values[index]==-1):\n",
    "                correct += 1\n",
    "                total += 1\n",
    "            elif(true_values[index]==1 and predicted_values[index]==-1):\n",
    "                total += 1\n",
    "            elif(true_values[index]==-1 and predicted_values[index]==1):\n",
    "                total += 1\n",
    "            else:\n",
    "                pass\n",
    "    return (correct/total)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** A generic utility function to find labels and polarity given a text **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to decode and print output labels and polarity for a review\n",
    "def output_to_labels(output):\n",
    "    '''\n",
    "     Description: Converts predicted output for a review into labels and polarity\n",
    "     Arguments: output a numpy array\n",
    "                \n",
    "    '''\n",
    "    labels = ['SERVICE#GENERAL', 'RESTAURANT#PRICES',\n",
    "       'RESTAURANT#MISCELLANEOUS', 'RESTAURANT#GENERAL', 'LOCATION#GENERAL',\n",
    "       'FOOD#STYLE_OPTIONS', 'FOOD#QUALITY', 'FOOD#PRICES',\n",
    "       'DRINKS#STYLE_OPTIONS', 'DRINKS#QUALITY', 'DRINKS#PRICES',\n",
    "       'AMBIENCE#GENERAL']\n",
    "    for index in range(len(labels)-1):\n",
    "        value = output[0,index]\n",
    "        if(value == 1):\n",
    "            print(labels[index],':',' ','positive')\n",
    "        elif(value == -1):\n",
    "            print(labels[index],':',' ','negative')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to decode and print output labels and polarity for a review\n",
    "def output_to_labels_multilabel(output):\n",
    "    '''\n",
    "     Description: Converts predicted output for a review into labels and polarity\n",
    "     Arguments: output a numpy array\n",
    "                \n",
    "    '''\n",
    "    labels = y_train_multliabel.columns.tolist()\n",
    "    for index in np.arange(len(labels)-1):\n",
    "        value = output[index]\n",
    "        if(value == 1):\n",
    "            print(labels[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to find aspects and sentiment polarity given a review\n",
    "def analyze_review(classifier, review_text,multilabel=False,standardizer=False):\n",
    "    '''\n",
    "    Description : Detects Aspects and finds the polarities given review text\n",
    "    Arguments : \n",
    "                review_text : A string with review sentence/sentences\n",
    "                classifier: A model used to predict the aspects and polarities\n",
    "    '''\n",
    "    dictionary = {'review':clean_text_data(review_text)}\n",
    "    df_input=pd.DataFrame(dictionary,index=np.arange(len(dictionary.keys())))\n",
    "    X = df_input['review']\n",
    "    if(standardizer):\n",
    "        X = standardizer.transform(X)\n",
    "    output = classifier.predict(X)\n",
    "    if(multilabel):\n",
    "        output_to_labels_multilabel(output[0])\n",
    "    else:\n",
    "        output_to_labels(output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make scoring function\n",
    "f1_scorer = make_scorer(compute_f1_score_micro, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Baseline Classifer (RandomForest with CountVectorizer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multioutput Multiclass**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator Parameters are: {'clf__estimator__n_estimators': 350} 0.726086723944\n",
      "F1-Score: 0.727958510136728\n",
      "Polarity Accuracy: 0.8407079646017699\n"
     ]
    }
   ],
   "source": [
    "#RandomForest Classifier\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(ngram_range=(1,2))),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier(max_depth=3,class_weight='balanced')))])\n",
    "#RandomForest specific parameters\n",
    "parameters = {\n",
    "'clf__estimator__n_estimators': [100,300,350]\n",
    "}\n",
    "#Find the optimal parameters for RandomForest\n",
    "model_parameter_selection = GridSearchCV(pipeline,param_grid=parameters,cv=5,scoring = f1_scorer)\n",
    "model_parameter_selection.fit(X_train, y_train)\n",
    "print(\"Best Estimator Parameters are:\",model_parameter_selection.best_params_, model_parameter_selection.best_score_)\n",
    "y_predicted = model_parameter_selection.predict(X_test)\n",
    "f1_micro=compute_f1_score_micro(y_test,y_predicted)\n",
    "polarity_accuracy = compute_polarity_accuracy_score(y_test,y_predicted)\n",
    "print('F1-Score:',f1_micro)\n",
    "print('Polarity Accuracy:',polarity_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multilabel only**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator Parameters are: {'clf__estimator__n_estimators': 350} 0.569367103467\n",
      "F1-Score: 0.609427609428\n"
     ]
    }
   ],
   "source": [
    "#RandomForest Classifier\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(ngram_range=(1,2))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier(max_depth=3,class_weight='balanced')))])\n",
    "#RandomForest specific parameters\n",
    "parameters = {\n",
    "'clf__estimator__n_estimators': [100,300,350]\n",
    "}\n",
    "#Find the optimal parameters for RandomForest\n",
    "model_parameter_selection = GridSearchCV(pipeline,param_grid=parameters,cv=5,scoring = 'f1_micro')\n",
    "model_parameter_selection.fit(X_train_multilabel, y_train_multliabel)\n",
    "print(\"Best Estimator Parameters are:\",model_parameter_selection.best_params_, model_parameter_selection.best_score_)\n",
    "y_predicted = model_parameter_selection.predict(X_test_multilabel)\n",
    "f1_score = metrics.f1_score(y_test_multilabel,y_predicted,average='micro')\n",
    "print('F1-Score:',f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Embeddings are dense low dimensional representation of words. Word Embeddings convert words from a vocabulary into vectors of real numbers. Word Embeddings have been used in many Sentiment Analysis tasks and have been found to be quite effective. An example model is given in <a href=\"http://www.cs.ubc.ca/~rjoty/paper/emnlp-paper-drnn-cr.pdf\" target=_blank>Fine-grained Opinion Mining with Recurrent Neural Networks and Word Embeddings</a>. Word Embeddings or Vector Space Models (VSM) place words with semantic similarity nearby in the vector space.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we can use Word Embeddings created from generic corpuses. It is a good idea to generate a domain specific Word Embeddings model as shown in <a href=\"http://nlp.stanford.edu/pubs/hamilton2016inducing.pdf\">Inducing Domain-Specific Sentiment Lexicons from Unlabeled Corpora</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yelp has made public a huge dataset as part of its data challenge program. We used the scripts available at <a href=\"https://github.com/titipata/yelp_dataset_challenge\" target=_blank>Yelp dataset challenge scripts</a> to create Word Embeddings. The scripts do not work with the latest version of Tensorflow (r0.12) and Python 3 so we had to modify them slightly. The updated scripts are available at <a href=\"https://github.com/umairacheema/yelp_dataset_challenge/tree/hotfix/python3x\"target=_blank>Yelp Util for Tensorflow r0.12</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The jupyter notebook to build domain specific word embedding for Restaurants is given in the aforementioned github repository as well. There are **21,892** restaurants and **9,90,627** reviews in the corpus used to build domain specific WordEmbeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The following code will not run in notebook as it requires the yelword2vec\n",
    "#created using code in \n",
    "#https://github.com/umairacheema/yelp_dataset_challenge/blob/hotfix/python3x/examples/domain_specific_word_embeddings.ipynb\n",
    "#yelpword2vec is 77M in size and cannot be uploaded to github\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "w2vmodel = Word2Vec.load_word2vec_format('data/yelpword2vec', binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to compute vectorized representation of a single review\n",
    "#Review should be a list of words\n",
    "def vectorize_review_w2v(w2vmodel,review,size=100):\n",
    "    '''\n",
    "    Description : Given word2vec model and review compute average\n",
    "                  feature vector\n",
    "    Arguments :\n",
    "                 w2vmodel : Trained word2vec model\n",
    "                 review : A single review as a list of words\n",
    "    '''\n",
    "    #Clean the review data\n",
    "    review = clean_text_data(review)\n",
    "    #Convert review into a list of words.\n",
    "    text = review.split()\n",
    "    word_count = 0\n",
    "    vector = np.zeros(size).reshape((1, size))\n",
    "    w2vmodel_words = set(w2vmodel.index2word)\n",
    "    for word in text:\n",
    "        if word in w2vmodel_words:\n",
    "            #vector += w2vmodel[word].reshape((1,size))\n",
    "            vector = np.add(vector,w2vmodel[word])\n",
    "            word_count += 1\n",
    "    if word_count>0:\n",
    "        vector = vector/word_count\n",
    "    return vector\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to vectorize multiple reviews using word2vec\n",
    "def vectorize_reviews_w2v(w2vmodel,reviews,size=100):\n",
    "    '''\n",
    "    Description: Given a Pandas Series with reviews, compute dense\n",
    "                 vectorized representation using Word2Vec\n",
    "    Arguments :\n",
    "                w2vmodel : Trained word2vec model\n",
    "                reviews: A Pandas series with all the reviews.\n",
    "    '''\n",
    "    #default value of 100 used by yelp_util\n",
    "    #Initialize a numpy array to store  feature vector for\n",
    "    #all reviews\n",
    "    vectorized_features = np.zeros((len(reviews),size),dtype='float32')\n",
    "    #Initialize a vector index\n",
    "    index = 0\n",
    "    for review in reviews:\n",
    "        vectorized_features[index] = vectorize_review_w2v(w2vmodel,review,size)\n",
    "        index += 1\n",
    "    return vectorized_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Convert training and testing features \n",
    "# into feature vectors\n",
    "training_features = vectorize_reviews_w2v(w2vmodel,X_train,size=100)\n",
    "testing_features = vectorize_reviews_w2v(w2vmodel,X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As RandomForest does not require Standardized features we are not doing feature scaling or standardization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Random Forest with Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def random_forest(training_features, testing_features):\n",
    "    rfclf = MultiOutputClassifier(RandomForestClassifier(class_weight='balanced'))\n",
    "    #RandomForest specific parameters\n",
    "    parameters = {\n",
    "    'estimator__n_estimators': [100,300,350],\n",
    "    'estimator__max_depth':[3,4,5]\n",
    "    }\n",
    "    #Find the optimal parameters for RandomForest\n",
    "    rf_parameter_selection = GridSearchCV(rfclf,param_grid=parameters,cv=5,scoring = f1_scorer)\n",
    "    rf_parameter_selection.fit(training_features, y_train)\n",
    "    print(\"Best Estimator Parameters are:\",rf_parameter_selection.best_params_, rf_parameter_selection.best_score_)\n",
    "    rf_y_predicted = rf_parameter_selection.predict(testing_features)\n",
    "    rf_f1_micro=compute_f1_score_micro(y_test,rf_y_predicted)\n",
    "    rf_polarity_accuracy = compute_polarity_accuracy_score(y_test,rf_y_predicted)\n",
    "    print('F1-Score:',f1_micro)\n",
    "    print('Polarity Accuracy:',polarity_accuracy)\n",
    "    return rf_parameter_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator Parameters are: {'estimator__max_depth': 5, 'estimator__n_estimators': 350} 0.71215408451\n",
      "F1-Score: 0.727958510136728\n",
      "Polarity Accuracy: 0.8407079646017699\n"
     ]
    }
   ],
   "source": [
    "rf=random_forest(training_features,testing_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Function to test on an unseen short review\n",
    "def classify_short_review(classifier,w2vmodel,size=100,standardizer=False,review=None):\n",
    "    review_text = \"I love the food. The service was terrible. I hated the ambience.\"\n",
    "    if(review):\n",
    "        review_text = review\n",
    "    cleaned = clean_text_data(review_text)\n",
    "    X=vectorize_review_w2v(w2vmodel,cleaned,size)\n",
    "    if(standardizer):\n",
    "        X=standardizer.transform(X)\n",
    "    predicted = classifier.predict(X)\n",
    "    print(output_to_labels(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SERVICE#GENERAL :   positive\n",
      "RESTAURANT#GENERAL :   positive\n",
      "FOOD#QUALITY :   positive\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "classify_short_review(rf,w2vmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Support Vector Machines with Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "def SVM(training_features, testing_features):\n",
    "    svmclf = MultiOutputClassifier(SVC(kernel='rbf'))\n",
    "    #Support Vector Machine specific parameters\n",
    "    parameters = {\n",
    "    'estimator__gamma': [0.0001,0.001,0.01,0.1],\n",
    "    'estimator__C':[0.1,1,10,100]\n",
    "    }\n",
    "    #As an additional step we need to standardize the features\n",
    "    training_features_std, testing_features_std, standardizer = standardize_features(training_features,testing_features) \n",
    "    #Find the optimal parameters for Support Vector Machine Classifier\n",
    "    svm_parameter_selection = GridSearchCV(svmclf,param_grid=parameters,cv=5,scoring = f1_scorer)\n",
    "    svm_parameter_selection.fit(training_features_std, y_train)\n",
    "    print(\"Best Estimator Parameters are:\",svm_parameter_selection.best_params_, svm_parameter_selection.best_score_)\n",
    "    svm_y_predicted = svm_parameter_selection.predict(testing_features_std)\n",
    "    svm_f1_micro=compute_f1_score_micro(y_test,svm_y_predicted)\n",
    "    svm_polarity_accuracy = compute_polarity_accuracy_score(y_test,svm_y_predicted)\n",
    "    print('SVM F1 Score:',svm_f1_micro)\n",
    "    print('SVM Polarity Accuracy:',svm_polarity_accuracy)\n",
    "    return svm_parameter_selection, standardizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator Parameters are: {'estimator__gamma': 0.001, 'estimator__C': 10} 0.733305052885\n",
      "SVM F1 Score: 0.7398895027624309\n",
      "SVM Polarity Accuracy: 0.9130434782608695\n"
     ]
    }
   ],
   "source": [
    "svm, standardizer=SVM(training_features,testing_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SERVICE#GENERAL :   positive\n",
      "RESTAURANT#GENERAL :   negative\n",
      "FOOD#QUALITY :   positive\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "classify_short_review(svm,w2vmodel,size=100,standardizer=standardizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It is important to note that even with fine tuned Support Vector Machines the test accuracy is not very high. This could mean that we need to improve our WordEmbeddings model. Previously we used a feature size of 300 as that was hardcoded in the yelp util. We also did not add the SemEval datasets while training the word2vec model. We now need to train a new Word2Vector model and train it on the corpus. We shall also try Continuous Bag of Words (CBOW) as well as Skip-n gram based models.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Support Vector Machines with Bigger Feature Size and CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The following code will not run in notebook as it requires the restaurant_reviews.pkl\n",
    "#created using code in\n",
    "#https://github.com/umairacheema/yelp_dataset_challenge/blob/hotfix/python3x/examples/domain_specific_word_embeddings.ipynb\n",
    "#restaurant_reviews.pkl is 740M in size and cannot be uploaded to github\n",
    "df_yelp_restaurant_reviews = pd.read_pickle('data/restaurant_reviews.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Combine the review data with the Semantic Evaluation data\n",
    "yelp_reviews_text = df_yelp_restaurant_reviews.text\n",
    "combined_reviews_text = pd.concat([yelp_reviews_text,X_train],axis=0)\n",
    "yelp_reviews_text = yelp_reviews_text.to_string(header=False,index=False)\n",
    "yelp_reviews_text = clean_text_data(yelp_reviews_text)\n",
    "#Save all reviews in a text file\n",
    "file = open('data/yelp_semeval_reviews.txt', 'w')\n",
    "file.write(yelp_reviews_text)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from gensim.models.word2vec import LineSentence\n",
    "#Convert it into a format that word2vec can understand\n",
    "linesentences = LineSentence('data/yelp_semeval_reviews.txt')\n",
    "#Build the model with higher number of features\n",
    "n_dims = 500\n",
    "cbow_model = Word2Vec(linesentences,size=n_dims,workers=multiprocessing.cpu_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Convert training and testing features \n",
    "# into feature vectors\n",
    "training_features_cbow = vectorize_reviews_w2v(cbow_model,X_train,size=n_dims)\n",
    "testing_features_cbow = vectorize_reviews_w2v(cbow_model,X_test,size=n_dims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator Parameters are: {'estimator__gamma': 0.0001, 'estimator__C': 10} 0.720127350354\n",
      "SVM F1 Score: 0.7338709677419355\n",
      "SVM Polarity Accuracy: 0.9066666666666666\n"
     ]
    }
   ],
   "source": [
    "svm_cbow, standardizer=SVM(training_features_cbow,testing_features_cbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Support Vector Machines with Skip gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Build a Skip gram model\n",
    "n_dims = 400\n",
    "sg_model = Word2Vec(linesentences,size=n_dims,workers=multiprocessing.cpu_count(),sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_features_sg = vectorize_reviews_w2v(sg_model,X_train,size=n_dims)\n",
    "testing_features_sg = vectorize_reviews_w2v(sg_model,X_test,size=n_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator Parameters are: {'estimator__gamma': 0.001, 'estimator__C': 10} 0.720292128109\n",
      "SVM F1 Score: 0.7517642175176422\n",
      "SVM Polarity Accuracy: 0.9066147859922179\n"
     ]
    }
   ],
   "source": [
    "svm_sg, standardizer = SVM(training_features_sg,testing_features_sg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) Support Vector Machines with gensim Phrase model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import Phrases\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create list of list of words.\n",
    "sentences = []\n",
    "for (index, row) in df_yelp_restaurant_reviews.iterrows():\n",
    "    text = df_yelp_restaurant_reviews.text[index]\n",
    "    cleaned = clean_text_data(text)\n",
    "    words = cleaned.split(\" \")\n",
    "    sentences.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 3310.154627084732\n"
     ]
    }
   ],
   "source": [
    "#This is a time consuming process\n",
    "#Takes approximately an hour on 2.2 GHz Intel Core i7 with 16G RAM\n",
    "import time\n",
    "start = time.time()\n",
    "bigram_transformer = Phrases(sentences)\n",
    "bigram_model = Word2Vec(bigram_transformer[sentences], size=500,workers=multiprocessing.cpu_count())\n",
    "time_elapsed =time.time()-start\n",
    "print('Time taken:',time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save the model as it is time consuming to build one\n",
    "bigram_model.save_word2vec_format('data/yelphraseword2vec',binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nigiri', 0.628957211971283),\n",
       " ('sashimi', 0.6185207366943359),\n",
       " ('ayce_sushi', 0.6114140748977661),\n",
       " ('raw_fish', 0.5325007438659668),\n",
       " ('california_rolls', 0.5213685035705566),\n",
       " ('dim_sum', 0.5194767713546753),\n",
       " ('ayce', 0.5128969550132751),\n",
       " ('rainbow_roll', 0.5115077495574951),\n",
       " ('ramen', 0.4964790940284729),\n",
       " ('maki_rolls', 0.48887306451797485)]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bg_model = Word2Vec.load_word2vec_format('data/yelphraseword2vec', binary=True)\n",
    "bg_model.most_similar('sushi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_dims=500\n",
    "training_features_bg = vectorize_reviews_w2v(bg_model,X_train,size=n_dims)\n",
    "testing_features_bg = vectorize_reviews_w2v(bg_model,X_test,size=n_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator Parameters are: {'estimator__gamma': 0.001, 'estimator__C': 10} 0.741167340589\n",
      "SVM F1 Score: 0.7648610265773991\n",
      "SVM Polarity Accuracy: 0.9132075471698113\n"
     ]
    }
   ],
   "source": [
    "svm_bg, standardizer = SVM(training_features_bg,testing_features_bg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10) SVM using Doc2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Use combined Yelp and SemEval Training datasets\n",
    "combined_sentences = []\n",
    "for review in combined_reviews_text:\n",
    "    review = clean_text_data(review)\n",
    "    words = review.split(\" \")\n",
    "    combined_sentences.append(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Train and Testing sentences\n",
    "train_sentences=[]\n",
    "for review in X_train:\n",
    "    review = clean_text_data(review)\n",
    "    words = review.split(\" \")\n",
    "    train_sentences.append(words)\n",
    "\n",
    "test_sentences = []  \n",
    "for review in X_test:\n",
    "    review = clean_text_data(review)\n",
    "    words = review.split(\" \")\n",
    "    test_sentences.append(words)\n",
    "#Yelp sentences\n",
    "unsupervised = []\n",
    "for (index, row) in df_yelp_restaurant_reviews.iterrows():\n",
    "    text = df_yelp_restaurant_reviews.text[index]\n",
    "    cleaned = clean_text_data(text)\n",
    "    words = cleaned.split(\" \")\n",
    "    unsupervised.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We are treating each review as a single sentence.\n",
    "# so we need to create LabeledSentences(required by GenSim)\n",
    "# Following resource was found quite useful for preparing Doc2Vec model\n",
    "#https://districtdatalabs.silvrback.com/modern-methods-for-sentiment-analysis\n",
    "\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "train_labeled_sentences = []\n",
    "for index in np.arange(len(train_sentences)):\n",
    "    train_labeled_sentences.append(LabeledSentence(train_sentences[index],'train_'+str(index)))\n",
    "\n",
    "test_labeled_sentences = []\n",
    "for index in np.arange(len(test_sentences)):\n",
    "    test_labeled_sentences.append(LabeledSentence(test_sentences[index],'test_'+str(index)))\n",
    "\n",
    "yelp_labeled_sentences = []\n",
    "for index in np.arange(len(unsupervised)):\n",
    "    yelp_labeled_sentences.append(LabeledSentence(unsupervised[index],'yelp_'+str(index)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 5686.786916971207\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from random import shuffle\n",
    "start = time.time()\n",
    "epochs = 10\n",
    "size = 100\n",
    "#Combined all tagged documents for building vocabulary\n",
    "tagged_docs = train_labeled_sentences+test_labeled_sentences+yelp_labeled_sentences\n",
    "doc2vmodel = Doc2Vec(tagged_docs,workers=multiprocessing.cpu_count(),size=size, window=10,min_count=2)\n",
    "time_elapsed =time.time()-start\n",
    "print('Time taken:',time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 334.805960893631\n"
     ]
    }
   ],
   "source": [
    "#Train the model using training data\n",
    "start = time.time()\n",
    "all_training_docs = train_labeled_sentences+yelp_labeled_sentences[1:40000]\n",
    "for epoch in range(epochs):\n",
    "    shuffle(all_training_docs)\n",
    "    doc2vmodel.train(all_training_docs)\n",
    "time_elapsed =time.time()-start\n",
    "print('Time taken:',time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Save the model\n",
    "\n",
    "#doc2vmodel.save('data/doc2vmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get training and testing features\n",
    "size=100\n",
    "training_features_d2v=np.zeros(shape=(len(train_sentences),size))\n",
    "for i,sentence in enumerate(train_sentences):\n",
    "    training_features_d2v[i] = doc2vmodel.infer_vector(sentence)\n",
    "    \n",
    "testing_features_d2v=np.zeros(shape=(len(test_sentences),size))\n",
    "\n",
    "for i,sentence in enumerate(test_sentences):\n",
    "    testing_features_d2v[i] = doc2vmodel.infer_vector(sentence)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator Parameters are: {'estimator__gamma': 0.01, 'estimator__C': 1} 0.684189018925\n",
      "SVM F1 Score: 0.7094642435685626\n",
      "SVM Polarity Accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "svm_d2v, standardizer = SVM(training_features_d2v,testing_features_d2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SERVICE#GENERAL            -1.0\n",
      "RESTAURANT#PRICES          -1.0\n",
      "RESTAURANT#MISCELLANEOUS    0.0\n",
      "RESTAURANT#GENERAL         -1.0\n",
      "LOCATION#GENERAL            0.0\n",
      "FOOD#STYLE_OPTIONS          0.0\n",
      "FOOD#QUALITY               -1.0\n",
      "FOOD#PRICES                -1.0\n",
      "DRINKS#STYLE_OPTIONS       -1.0\n",
      "DRINKS#QUALITY              0.0\n",
      "DRINKS#PRICES              -1.0\n",
      "AMBIENCE#GENERAL            1.0\n",
      "Name: 88, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Test it on X_test[88]\n",
    "print(y_test.iloc[88])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "review = X_test[88]\n",
    "review=clean_text_data(review)\n",
    "sentence = review.split(\" \")\n",
    "vector = doc2vmodel.infer_vector(sentence)\n",
    "vector = vector.reshape(1,100)\n",
    "vector = standardizer.transform(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "predicted = svm_d2v.predict(vector)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESTAURANT#GENERAL :   positive\n",
      "FOOD#QUALITY :   positive\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "classify_short_review(svm_d2v,doc2vmodel,size=100,standardizer=standardizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
